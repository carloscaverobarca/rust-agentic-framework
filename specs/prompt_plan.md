# ðŸ—‚ï¸ Prompt Plan for Agentic Chatbot Backend (Rust)

This document provides:

1. **Detailed Blueprint** â€“ a stepâ€‘byâ€‘step implementation plan derived from `agentic_chatbot_spec.md`.
2. **Incremental Roadmap** â€“ phases â†’ chunks â†’ atomic steps.
3. **LLM Codeâ€‘Generation Prompts** â€“ readyâ€‘toâ€‘copy prompts (tagged as `text`) for a codeâ€‘generation model to implement each step in a testâ€‘driven workflow.

---

## 1. Implementation Blueprint

### 1.1 Repository Layout
```
agentic_chatbot/
â”œâ”€â”€ Cargo.toml              # workspace root
â”œâ”€â”€ crates/
â”‚   â”œâ”€â”€ core/               # shared types, config, errors
â”‚   â”œâ”€â”€ server/             # Axum HTTP & SSE
â”‚   â”œâ”€â”€ embeddings/         # Cohere client, text chunker
â”‚   â”œâ”€â”€ vector_store/       # pgvector integration
â”‚   â”œâ”€â”€ llm/                # Bedrock Claude wrapper
â”‚   â””â”€â”€ tooling/            # file_summarizer + registry
â””â”€â”€ tests/                  # integration tests
```

### 1.2 Module Responsibilities
| Crate / Module | Purpose |
|----------------|---------|
| **core** | Config loader, message types, session store, custom errors |
| **embeddings** | Document chunking, Cohere embeddings + fallback |
| **vector_store** | pgvector schema & similarity search |
| **llm** | Bedrock Claude Sonnet v4 wrapper + 3.7 fallback |
| **tooling** | `Tool` trait, registry, `file_summarizer` |
| **server** | Axum routes, SSE streaming, agent loop |

### 1.3 Data Flow
1. Client sends request to `/predict_stream`.
2. Server loads session history, detects tool usage.
3. Executes `file_summarizer` if needed â†’ emits `tool_usage` SSE.
4. Retrieves relevant chunks from `vector_store`.
5. Calls `llm` with prompt + context; streams `assistant_output`.
6. Updates session history.

### 1.4 Error Handling
| Layer | Error | Strategy |
|-------|-------|----------|
| Tool | FileNotFound | Send `tool_usage` event with `"error": "FileNotFound"` |
| Embedding | Cohere 5xx | Exponential backoff Ã—3 then 500 |
| LLM | Timeout | Retry once with fallback model |
| SSE | Disconnect | Close stream gracefully |
| DB | Connection lost | Reconnect once then 500 |

### 1.5 Testing
- **Unit**: Perâ€‘crate logic.
- **Integration**: Endâ€‘toâ€‘end chat with dockerised Postgres & mocked external APIs.
- **CI**: GitHub Actions â€“ `fmt`, `clippy`, tests.

---

## 2. Incremental Roadmap

| Phase | Goal | Chunks |
|-------|------|--------|
| 0 | Foundation | 0â€‘A Init workspace â€¢ 0â€‘B CI |
| 1 | Core Types & Config | 1â€‘A Message enum â€¢ 1â€‘B Config loader â€¢ 1â€‘C SessionStore |
| 2 | Server Skeleton | 2â€‘A Axum setup â€¢ 2â€‘B SSE utils â€¢ 2â€‘C Stub endpoint |
| 3 | Embeddings | 3â€‘A Chunker â€¢ 3â€‘B Cohere client â€¢ 3â€‘C Fallback stub |
| 4 | Vector Store | 4â€‘A Migration â€¢ 4â€‘B Insert â€¢ 4â€‘C Query |
| 5 | LLM Wrapper | 5â€‘A Credentials â€¢ 5â€‘B Sonnet v4 call â€¢ 5â€‘C Fallback retry |
| 6 | Tooling | 6â€‘A Trait & registry â€¢ 6â€‘B file_summarizer â€¢ 6â€‘C Keyword detector |
| 7 | Agent & SSE | 7â€‘A Agent loop â€¢ 7â€‘B tool_usage event â€¢ 7â€‘C assistant_output stream |
| 8 | Polish & Tests | 8â€‘A Error types â€¢ 8â€‘B Integration tests â€¢ 8â€‘C Docs & sample config |

---

## 3. Atomic Step Tree

Example for **PhaseÂ 2 â€“ Server Skeleton**:

| ID | Step |
|----|------|
| 2â€‘Aâ€‘1 | Add `axum = "0.7"` & `tokio` deps to `server/Cargo.toml`. |
| 2â€‘Aâ€‘2 | Create `server/src/main.rs` with `#[tokio::main]` + `Router::new().route("/health", get(|| async {"ok"}))`. |
| 2â€‘Aâ€‘3 | Add unit test hitting `/health` using `tower::ServiceExt`. |
| â€¦ | â€¦ |

*(The full atomic list accompanies each prompt section below.)*

---

## 4. LLM Codeâ€‘Generation Prompts

> Feed prompts **sequentially**.  
> After each generated diff, run tests; proceed only when green.

### Prompt Formatting
```text
ðŸ”– <ID>
<Instruction>
```

### PhaseÂ 0 â€“ Foundation

```text
ðŸ”– 0â€‘Aâ€‘1
Create a new Cargo **workspace** named `agentic_chatbot`.  
Add a root `Cargo.toml` with `[workspace] members = ["crates/*"]` and `.gitignore` (Rust + VSCode).  
Do NOT create any crates yet.  
Return the complete file list and contents.
```

```text
ðŸ”– 0â€‘Aâ€‘2
Inside `crates`, scaffold two crates:  
1. `core` (library) with empty `lib.rs`.  
2. `server` (binary) with `main.rs` printing "stub".  
Update workspace `Cargo.toml`.  
Ensure `cargo check` passes.
```

```text
ðŸ”– 0â€‘Bâ€‘1
Add GitHub Actions workflow `.github/workflows/ci.yml` that on `push`/`pull_request`:  
- Sets up Rust stable.  
- Runs `cargo fmt -- --check`, `cargo clippy --all -- -D warnings`, `cargo test`.  
Provide full YAML.
```

### PhaseÂ 1 â€“ Core Types & Config

```text
ðŸ”– 1â€‘Aâ€‘1
In `core`, define enum `Role { User, Assistant, Tool }` and struct `Message { role: Role, content: String, name: Option<String> }` with serde derive + unit tests for serialization.
```

```text
ðŸ”– 1â€‘Bâ€‘1
Implement `Config` struct in `core` with fields mirroring `config.toml`.  
Add `config::load()` that reads `CONFIG_PATH` env (default `./config.toml`).  
Unit test with a temp file.
```

```text
ðŸ”– 1â€‘Câ€‘1
Add `SessionStore` struct (HashMap<Uuid, Vec<Message>>) with methods `get`, `append`, `gc(ttl_secs)`.  
Cover with unit tests using `tokio::time::pause`.
```

*(Continue prompts for all phases through 8â€‘Câ€‘3. Each atomic prompt is < ~150 tokens, ensuring small, testable steps.)*

---

**End of prompt_plan.md**